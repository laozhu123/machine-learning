
姿势动作图像
HMDB_a large human motion database
Human Actionsand Scenes Dataset
Buffy Stickmen V3 人体轮廓识别图像数据
Human Pose Evaluator 人体轮廓识别图像数据
Buffy pose 人类姿势图像数据
VGG Human Pose Estimation 姿势图像标注数据

人类动作视频
Microsoft Research Action 人类动作视频数据

UT-Interaction 人类动作视频数据

HMDB 人类动作视频
HOLLYWOOD2 人类行为动作视频数据
Recognition of human actions 动作视频数据
Motion Capture 动作捕捉视频数据
SBU Kinect Interaction 肢体动作视频数据
Human Actions 动作识别数据
     UCF101 https://www.crcv.ucf.edu/data/UCF101.php
     UCF50  https://www.crcv.ucf.edu/data/UCF50.php
     UCF11(YouTube Action)  https://www.crcv.ucf.edu/data/UCF_YouTube_Action.php
     UCF Sports Action https://www.crcv.ucf.edu/data/UCF_Sports_Action.php
     UCF Aerial Action https://www.crcv.ucf.edu/data/UCF_Aerial_Action.php
     UCF-ARG
     UCF-iPhone https://www.crcv.ucf.edu/data/UCF-iPhone.php
     THUMOS Contest
Crowd Counting
     UCF-CC-50 https://www.crcv.ucf.edu/data/ucf-cc-50/
     UCF-QNRF https://www.crcv.ucf.edu/data/ucf-qnrf/
Crowd Segmentation https://www.crcv.ucf.edu/data/crowd.php
CLIF Data Set Ground Truth https://www.crcv.ucf.edu/data/CLIF.php
Tracking in High Density Crowds https://www.crcv.ucf.edu/data/tracking.php
PNNL Parking Lot https://www.crcv.ucf.edu/data/ParkingLOT
Fire Detection in Video Sequences https://www.crcv.ucf.edu/data/fire.php
VIRAT https://www.crcv.ucf.edu/data/VIRAT.php
Motion Capture https://www.crcv.ucf.edu/data/mocap.php
ALOV++ https://www.crcv.ucf.edu/data/ALOV++
Google Street View https://www.crcv.ucf.edu/data/GMCP_Geolocalization
Selfie https://www.crcv.ucf.edu/data/Selfie

1. Weizmann 人体行为库

此数据库一共包括90段视频，这些视频分别是由9个人执行了10个不同的动作（bend, jack, jump, pjump, run, side, skip, walk, wave1,wave2）。视频的背景，视角以及摄像头都是静止的。而且该数据库提供标注好的前景轮廓视频。不过此数据库的正确率已经达到100%了，现在发文章基本没人用了呀。下载地址：http://www.wisdom.weizmann.ac.il/~vision/SpaceTimeActions.html





2. KTH人体行为数据库
该数据库包括6类行为（walking, jogging, running, boxing, hand waving, hand clapping）,是由25个不同的人执行的，分别在四个场景下，一共有599段视频。背景相对静止，除了镜头的拉近拉远，摄像机的运动比较轻微。这个数据库是现在的benchmark，正确率需要达到95.5%以上才能够发文章。下载地址：http://www.nada.kth.se/cvap/actions/






3. INRIA XMAX多视角视频库
该数据库从五个视角获得，一共11个人执行14种行为。室内四个方向和头顶一共安装5个摄像头。另外背景和光照基本不变。下载地址：http://4drepository.inrialpes.fr/public/viewgroup/6






4. UCF Sports 数据库
该视频包括150段关于体育的视频，一共有13个动作。实验室采用留一交叉验证法。2011年cvpr有几篇都用这个数据库，正确率要达到87%才能发文章。下载地址：http://vision.eecs.ucf.edu/data.html




5. Hollywood 人体行为库
该数据库包括8类行为。这些都是电影中的片段。 下载地址：http://www.di.ens.fr/~laptev/actions/hollywood2/








6. Olympic sports dataset

该数据库有16种行为，783段视频。现在的正确率大约在75%左右。下载地址：http://vision.stanford.edu/Datasets/OlympicSports/




7. UIUC action dataset

这个数据库已经做到98%了，建议不要去做了。下载地址：http://vision.cs.uiuc.edu/projects/activity/


8. TRECVID视频库

1.HMDB51

来源为YouTube视频，共计51类动作，约7000段视频。数据库主页为：HMDB: a large human motion database

2. KTH人体行为数据库

该数据库包括6类行为（walking,jogging, running, boxing, hand waving, hand clapping）,是由25个不同的人执行的，分别在四个场景下，一共有599段视频。背景相对静止。正确率需要达到95.5%以上才能够发文章。下载地址：http://www.nada.kth.se/cvap/actions/

3. INRIA XMAX多视角视频库

该数据库从五个视角获得，一共11个人执行14种行为。室内四个方向和头顶一共安装5个摄像头。另外背景和光照基本不变。下载地址：http://4drepository.inrialpes.fr/public/viewgroup/6

4. UCF Sports 数据库

该视频包括150段关于体育的视频，一共有13个动作。实验室采用留一交叉验证法。2011年cvpr有几篇都用这个数据库，正确率要达到87%才能发文章。下载地址：http://vision.eecs.ucf.edu/data.html

5. Hollywood 人体行为库

该数据库包括8类行为。这些都是电影中的片段。 下载地址：http://www.di.ens.fr/~laptev/actions/hollywood2/

6. Olympic sports dataset

该数据库有16种行为，783段视频。现在的正确率大约在75%左右。下载地址：http://vision.stanford.edu/Datasets/OlympicSports/

7. 谷歌AVA dataset

是YouTube上提取的被标注的80个原子动作。共5.8万个片段，包含握手、踢腿、拥抱、接吻、喝酒、玩乐器、散步等日常活动。下载地址：https://research.google.com/ava/


.1    Weizmann
　　Weizmann[27]数据库包含了10个动作分别是走，跑，跳，飞跳，向一侧移动，单只手挥动，2只手挥动，单跳，2只手臂挥动起跳,每个动作有10个人执行。在这个视频集中，其背景是静止的，且前景提供了剪影信息。该数据集较为简单。
1.2    KTH
　　KTH[45]行人数据库包含了6种动作，分别为走，慢跑，跑挥手和鼓掌。每种动作由25个不同的人完成。每个人在完成这些动作时又是在4个不同的场景中完成的，4个场景分别为室外，室内，室外放大，室外且穿不同颜色的衣服。
网址链接2：http://www.nada.kth.se/cvap/actions/
1.3    PETS
　　PETS[51]，其全称为跟踪与监控性能评估会议，它的数据库是从现实生活中获取的，主要来源于直接从视频监控系统拍摄的视频，比如说超市的监控系统。从2000年以后，基本上每年都会组织召开这个会议。
1.4    YouTube
   YouTube包含11类动作，因为是现实生活中的视频数据，所以其背景比较复杂，这些种类的动作识别起来有些困难。
网址链接3：http://www.cs.ucf.edu/-liujg/YouTube\_Action\_dataset.html
1.5    UCF Sports
    UCF包含几个数据集，这里是指UCF的运动数据库,该视频数据包括了182个视频序列，共有9类动作。因为是现实生活中的视频数据，所以其背景比较复杂，这些种类的动作识别起来有些困难。
1.6    INRIA XMAS
　　INRIA XMAS数据库[53]是从5个视角拍摄的，室内的4个方向和头顶的1个方向。总共有11个人完成14种不同的动作，动作可以沿着任意方向执行。摄像机是静止的，环境的光照条件也基本不变。另外该数据集还提供有人体轮廓和体积元等信息。
1.7    Hollywood与Hollywood2
　　Hollywood电影的数据库包含有几个，其一Hollywood的视频集有8种动作，分别是接电话，下轿车，握手，拥抱，接吻，坐下，起立，站立。这些动作都是从电影中直接抽取的，由不同的演员在不同的环境下演的。其二Hollywood2在上面的基础上又增加了4个动作，骑车，吃饭，打架，跑。并且其训练集给出了电影的自动描述文本标注，另外一些是由人工标注的。因为有遮挡，移动摄像机，动态背景等因素，所以这个数据集非常有挑战。
1.8    HMDB51
    HMDB51包含51类动作，共有6849个视频，其中作者提供了70%用于训练，剩下的用于测试，320*240,。来自于YouTube、movie和其他的。
http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads 
1.9    UCF101
    UCF101包含101类动作，其中每一类由25个人做动作，每个人做4-7组，共有13320个视频，320*240.  

网址链接4：http://crcv.ucf.edu/data/UCF101/UCF101.rar

1.Weizman-包含10种动作(走路、快跑、向前跳、测试跳、弯腰、挥单手、原地跳、全身跳、单腿跳)，每个动作由10个人来掩饰，背景固定并且前景轮廓已经包含在数据库中，视角固定。

2.KTH-包含6种动作(走、跳、跑、击拳、挥手、拍手)，由25个人执行，分别在四个场景下，共599段视频，除了镜头的拉近拉远、摄像机的轻微运动外，背景相对静止。

3.UCF Sports-包含10类动作(跳水、打高尔夫、踢腿、举重、骑马、跑步、滑板、摇摆、侧摆、走路)，150个视频，从广播体育频道上收集到的，涵盖很广的场景类型和视角区域。

4.UCF50/UCF101-包含50/101类动作，6680段视频，都是网络上的视频，是真实场景下的。

5.Hollywood(2)-包含12类动作，2859个视频，从电影中截取的

6. HMDB-包含51类动作，6849个视频，由布朗大学SERRE实验室发布。

7.IXMAS Action-包含17类动作，是多角度行为数据，由8个视频角度的摄像机同时对一个行为进行拍摄。由英国Kingston大学发布.中科院自动化所发布了类似的数据集，CASIA.

8.UT-Interaction-监控场景下的数据库，识别从简单的单人行为上升到多人的交互行为。

9.MSR Action 3D/MSR Daily Activity 3D-利用Kinect传感器捕获除彩色图像以外的人体深度图像序列，利用Kinect采集的深度数据可获取较为精准的人体关节点骨架序列，这些序列为深入研究人体运动模式提供了很好的研究数据。

10.Northwestern-UCLA Multiview Action 3D-将深度、骨架和多视角数据融合在一起。

11.CUM Motion Capture-利用8个红外摄像头对41个标记点的人体进行重构，更为准确的估计出人体的骨架结构。


12.Activities of Daily Living(ADL)和First Person Social Interaction—用可穿戴设备采集的第一人称视角的行为数据库

1. The KTH Dataset(2004)
KTH数据集于2004 年的发布,是计算机视觉领域的一个里程碑。此后，许多新的数据库陆续发布。数据库包括在 4个不同场景下 25 个人完成的 6 类动作(walking, jogging, running,boxing, hand waving and hand clapping)共计 2391个视频样本，是当时拍摄的最大的人体动作数据库，它使得采用同样的输入数据对不同算法的性能作系统的评估成为可能。数据库的视频样本中包含了尺度变化、 衣着变化和光照变化，但其背景比较单一，相机也是固定的。下载地址：http://www.nada.kth.se/cvap/actions/
但是现在该数据集无法下载了(本人在这个网站中未能下载下)；发现数据堂上面有，有点贵。本人有一份，free。
 
2. The Weizmann Dataset(2005)
2005年，以色列 Weizmann institute 发布了Weizmann 数据库。数据库包含了 10个动作（bend, jack, jump, pjump, run,side, skip, walk, wave1,wave2），每个动作有 9 个不同的样本。视频的视角是固定的，背景相对简单，每一帧中只有 1 个人做动作。数据库中标定数据除了类别标记外还包括:前景的行为人剪影和用于背景抽取的背景序列。下载地址：http://www.wisdom.weizmann.ac.il/~vision/SpaceTimeActions.html
KTH 和 Weizmann 数据库是行为识别领域引用率最高的数据库，对行为识别的研究起了较大的促进作用。当然，这两个数据库的局限性也是很明显的，由于背景比较简单，没有包含相机运动， 动作种类也较少，并且每段视频只有1个人在做单一的运动，这与真实的场景差别很大。
3. The IXMAS Dataset(2006)
该数据库为多视角数据库，该数据库从五个视角获得，室内四个方向和头顶一共安装5个摄像头，另外背景和光照基本不变。包含了11个人做14个动作，重复3次，这14个动作包括{check watch, cross arms, scratch head, sit down, get up, turnaround, walk, wave, punch, kick, point, pick up, throw (over head), throw (frombottom up)}。下载地址：http://4drepository.inrialpes.fr/public/viewgroup/6
 
4. The Hollywood Dataset(2008、2009)
Hollywood(2008年发布)、Hollywood-2数据库是由法国IRISA研究院发布的。早先发布的数据库基本上都是在受控的环境下拍摄的，所拍摄视频样本有限。2009年发布的Hollywood-2是Hollywood数据库的拓展版，包含了 12 个动作类别和 10个场景共3669个样本，所有样本均是从69部 Hollywood 电影中抽取出来的。视频样本中行为人的表情、姿态、穿着，以及相机运动、光照变化、遮挡、背景等变化很大，接近于真实场景下的情况，因而对于行为的分析识别极具挑战性。下载地址：http://www.di.ens.fr/~laptev/actions/hollywood2/
 
5. The UCF Dataset(2007-)
美国University of central Florida(UCF)自2007年以来发布的一系列数据库：1UCF sports action dataset(2008)，2UCF Youtube(2008)，3UCF50，4UCF101，引起了广泛关注。这些数据库样本来自从 BBC/ESPN的广播电视频道收集的各类运动样本、以及从互联网尤其是视频网站YouTube上下载而来的样本。其中UCF101是目前动作类别数、样本数最多的数据库之一，样本为13320段视频，类别数为101类。
下载地址：http://crcv.ucf.edu/data/
  
6. The Olympic sports dataset UCF sports action dataset(2010)
Stanford university2010年发布Olympic sports dataset UCF sports action dataset，包含了运动员的各类运动视频。视频都是从YouTube上下载的，包含有16个运动类别的50个视频，标记信息为运动类别。
下载地址：http://vision.stanford.edu/Datasets/OlympicSports/

7. The UT-interactiondataset
UT-interaction database是针对交互行为的数据库，包含有6类人人交互的动作(shaking hands, pointing, hugging,pushing, kicking and punching)总共 20 段样本,长度在 1 min 左右。
下载地址：http://cvrc.ece.utexas.edu/SDHA2010/Human_Interaction.html

8. The VideoWebdataset(2010)
California大学的VideoWebdatabase于 2010年发布，该数据库重点放在多人间的非语言交流的行为上(non-verbal communication),包含由最少4个至第4期视频序列中的行为识别研究进展多8个摄像机拍摄的长度为2.5min的视频。(未找到链接)


9. The HMDB51 dataset(2011)
Brown university大学发布的HMDB51于2011年发布，视频多数来源于电影，还有一部分来自公共数据库以及YouTube等网络视频库。数据库包含有6849段样本，分为51类，每类至少包含有101段样本。
下载地址：http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#dataset
 
除此之外还有：CMU MoBo DataSet(2001)、CMU MoCapDataSet(2006)、Human Eva(2009)、i3DPostMultiView(2009)

总体而言，数据库的动作类别越来越多，样本越来越多，数据库也更庞大，视频场景越来越复杂。较早的数据库，比如KTH，视频背景较简单，动作类别不多，相机固定，这使得现有的算法很容易达到饱和，不好区分算法的优劣。最近几年发布的数据库有如下几个趋势：背景嘈杂，视角不固定，甚至相机是运动的; 样本涉及到人人交互，人物交互；行为类别数较最早发布的数据库多了很多，总之是更接近于不受控的自然状态下的情景，这对于算法的鲁棒性提出了很大的挑战。

 

 ## 行人检测数据库
MIT cbcl (center for biological and computational learning)Pedestrian Data 

 该数据集主要包含2个部分，一部分为924张行人图片（ppm格式，宽高为64x128），只含正面和背面两个视角，肩到脚的距离约80象素，无负样本，未区分训练集和测试集，“HOG+SVM”，在该数据库上的检测准确率接近100%，另一部分为从打图中分别切割而出的小图，主要包含胳膊，脑袋，脚，腿，头肩，身体等。下载链接为http://cbcl.mit.edu/software-datasets/PedestrianData.html

INRIA Person Dataset

 Inria数据集是最常使用的静态行人检测数据集。其中正样本（行人）为png格式，负样本为jpg格式。训练集有正样本614张（包含2416个行人），负样本1218张；测试集有正样本288张（包含1126个行人），负样本453张。图片中人体大部分为站立姿势且高度大于100个象素，部分标注可能不正确。图片主要来源于GRAZ-01、个人照片及google。里面的图片分为只有车，只有人，有车有人，无车无人四个类别。图片像素为70*134，96*160，64*128等。下载链接为http://pascal.inrialpes.fr/data/human/


Caltech Pedestrian Detection Benchmark

加州理工学院的步行数据集包含大约包含10个小时640x480 30Hz的视频。目前规模较大的行人数据库，其主要是在一个在行驶在乡村街道的小车上拍摄。该数据库是约10个小时左右，视频的分辨率为640x480，30帧/秒。标注了约250,000帧（约137分钟），350000个矩形框，2300个行人，另外还对矩形框之间的时间对应关系及其遮挡的情况进行标注，包括包围盒和详细的闭塞标签之间的时间对应关系。数据集分为set00~set10，其中set00~set05为训练集，set06~set10为测试集（标注信息尚未公开）。性能评估方法有以下三种：（1）用外部数据进行训练，在set06~set10进行测试；（2）6-fold交叉验证，选择其中的5个做训练，另外一个做测试，调整参数，最后给出训练集上的性能；（3）用set00~set05训练，set06~set10做测试。由于测试集的标注信息没有公开，需要提交给PitorDollar。结果提交方法为每30帧做一个测试，将结果保存在txt文档中（文件的命名方式为I00029.txt I00059.txt ……），每个txt文件中的每行表示检测到一个行人，格式为“[left, top,width, height, score]”。如果没有检测到任何行人，则txt文档为空。该数据库还提供了相应的Matlab工具包，包括视频标注信息的读取、画ROC（Receiver Operatingcharacteristic Curve）曲线图和非极大值抑制等工具。
。
更多信息可在其PAMI 2012 CVPR 2009标杆的论文获得。下载链接为http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/



Daimler行人数据库

    该数据库采用车载摄像机获取，分为检测和分类两个数据集。检测数据集的训练样本集有正样本大小为18x36和48x96的图片各15560（3915x4）张，行人的最小高度为72个象素；负样本6744张（大小为640x480或360x288）。测试集为一段27分钟左右的视频（分辨率为640x480），共21790张图片，包含56492个行人。分类数据库有三个训练集和两个测试集，每个数据集有4800张行人图片，5000张非行人图片，大小均为18x36，另外还有3个辅助的非行人图片集，各1200张图片。


TUD行人数据库

    TUD行人数据库为评估运动信息在行人检测中的作用，提供图像对以便计算光流信息。训练集的正样本为1092对图像（图片大小为720x576，包含1776个行人）；负样本为192对非行人图像（手持摄像机85对，车载摄像机107对）；另外还提供26对车载摄像机拍摄的图像（包含183个行人）作为附加训练集。测试集有508对图像（图像对的时间间隔为1秒，分辨率为640x480），共有1326个行人。Andriluka等也构建了一个数据库用于验证他们提出的检测与跟踪相结合的行人检测技术。该数据集的训练集提供了行人的矩形框信息、分割掩膜及其各部位（脚、小腿、大腿、躯干和头部）的大小和位置信息。测试集为250张图片（包含311个完全可见的行人）用于测试检测器的性能，2个视频序列（TUD-Campus和TUD-Crossing）用于评估跟踪器的性能。

NICTA行人数据库

    该数据库是目前规模较大的静态图像行人数据库，25551张含单人的图片，5207张高分辨率非行人图片，数据库中已分好训练集和测试集，方便不同分类器的比较。Overett等用“RealBoost+Haar”评估训练样本的平移、旋转和宽高比等各种因素对分类性能的影响：（1）行人高度至少要大于40个象素；（2）在低分辨率下，对于Haar特征来说，增加样本宽度的性能好于增加样本高度的性能；（3）训练图片的大小要大于行人的实际大小，即背景信息有助于提高性能；（4）对训练样本进行平移提高检测性能，旋转对性能的提高影响不大。以上的结论对于构建行人数据库具有很好的指导意义。

ETH行人数据库

     Ess等构建了基于双目视觉的行人数据库用于多人的行人检测与跟踪研究。该数据库采用一对车载的AVT Marlins F033C摄像头进行拍摄，分辨率为640x480，帧率13-14fps，给出标定信息和行人标注信息，深度信息采用置信度传播方法获取。

CVC行人数据库

    该数据库目前包含三个数据集（CVC-01、CVC-02和CVC-Virtual），主要用于车辆辅助驾驶中的行人检测研究。CVC-01[Geronimo,2007]有1000个行人样本，6175个非行人样本（来自于图片中公路区域中的非行人图片，不像有的行人数据库非行人样本为天空、沙滩和树木等自然图像）。CVC-02包含三个子数据集（CVC-02-CG、CVC-02-Classification和CVC-02-System），分别针对行人检测的三个不同任务：感兴趣区域的产生、分类和系统性能评估。图像的采集采用Bumblebee2立体彩色视觉系统，分辨率640x480，焦距6mm，对距离摄像头0~50m的行人进行标注，最小的行人图片为12x24。CVC-02-CG主要针对候选区域的产生，有100张彩色图像，包含深度和3D点信息；CVC-02-Classification主要针对行人分类，训练集有1016张正样本，7650张负样本，测试集分为基于切割窗口的分类（570张行人，7500张非行人）和整张图片的检测（250张包含行人的图片，共587个行人）；CVC-02-System主要用于系统的性能评估，包含15个视频序列（4364帧），7983个行人。CVC-Virtual是通过Half-Life 2图像引擎产生的虚拟行人数据集，共包含1678虚拟行人，2048个非行人图片用于测试。

USC行人数据库

    该数据库包含三组数据集（USC-A、USC-B和USC-C），以XML格式提供标注信息。USC-A[Wu, 2005]的图片来自于网络，共205张图片，313个站立的行人，行人间不存在相互遮挡，拍摄角度为正面或者背面；USC-B的图片主要来自于CAVIAR视频库，包括各种视角的行人，行人之间有的相互遮挡，共54张图片，271个行人；USC-C有100张图片来自网络的图片，232个行人（多角度），行人之间无相互遮挡。

