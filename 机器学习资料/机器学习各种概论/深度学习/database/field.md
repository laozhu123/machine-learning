
金融
美国劳工部统计局官方发布数据
房地产公司 Zillow 公开美国房地产历史数据
沪深股票除权除息、配股增发全量数据，截止 2016.12.31
上证主板日线数据，截止 2017.05.05，原始价、前复权价、后复权价，1260支股票
深证主板日线数据，截止 2017.05.05，原始价、前复权价、后复权价，466支股票
深证中小板日线数据，截止 2017.05.05，原始价、前复权价、后复权价，852支股票
深证创业板日线数据，截止 2017.05.05，原始价、前复权价、后复权价，636支股票
上证A股日线数据，1999.12.09至 2016.06.08，前复权，1095支股票
深证A股日线数据，1999.12.09至 2016.06.08，前复权，1766支股票
深证创业板日线数据，1999.12.09 至2016.06.08，前复权，510支股票
MT4平台外汇交易历史数据
Forex平台外汇交易历史数据
几组外汇交易逐笔（Ticks）数据
美国股票新闻数据【Kaggle数据】
美国医疗保险市场数据【Kaggle数据】
美国金融客户投诉数据【Kaggle数据】
Lending Club 网贷违约数据【Kaggle数据】
信用卡欺诈数据【Kaggle数据】
美国股票数据XBRL【Kaggle数据】
纽约股票交易所数据【Kaggle数据】
贷款违约预测竞赛数据【Kaggle竞赛】
Zillow 网站房地产价值预测竞赛数据【Kaggle竞赛】
Sberbank 俄罗斯房地产价值预测竞赛数据【Kaggle竞赛】
Homesite 保险定价竞赛数据【Kaggle竞赛】
Winton 股票回报率预测竞赛数据【Kaggle竞赛】
房屋租赁信息查询次数预测竞赛【Kaggle竞赛】


交通
2013年纽约出租车行驶数据
2013年芝加哥出租车行驶数据
Udacity自动驾驶数据
纽约Uber 接客数据 【Kaggle数据】
英国车祸数据（2005-2015）【Kaagle数据】
芝加哥汽车超速数据【Kaggle数据】
KITTI 自动驾驶任务数据【数据太大仅有部分】
Cityscapes 场景标注数据【数据太大仅有部分】
德国交通标志识别数据
交通信号识别数据
芝加哥Divvy共享自行车骑行数据（2013年至今）
美国查塔努加市共享单车骑行数据
Capital 共享单车骑行数据
Bay Area 共享单车骑行数据
Nice Ride 共享单车骑行数据
花旗银行共享单车骑行数据
运用卫星数据跟踪亚马逊热带雨林中的人类轨迹竞赛【Kaggle竞赛】
纽约出租车管理委员会官方的乘车数据（2009年-2016年）

商业
Airbnb 开放的民宿信息和住客评论数据
Amazon 食品评论数据【Kaggle数据】
Amazon 无锁手机评论数据【Kaggle数据】
美国视频游戏销售和评价数据【Kaggle数据】
Kaggle 各项竞赛情况数据【Kaggle数据】
Bosch 生产流水线降低次品率竞赛数据【Kaggle竞赛】
预测公寓租金竞赛数据
广告点击预测竞赛数据
餐厅营业收入预测建模竞赛
银行产品推荐竞赛数据
网站用户推荐点击预测竞赛数据
在线广告实时竞价数据【Kaggle数据】
购物车商品关联竞赛数据【Kaggle竞赛】
Airbnb 新用户的民宿预定预测竞赛数据【Kaggle竞赛】
Yelp 点评网站公开数据
KKBOX 音乐用户续订预测竞赛【Kaggle竞赛】
Grupo Bimbo 面包店库存和销量预测竞赛【Kaggle竞赛】


一、图像数据集
1.MNIST
https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/
640?wx_fmt=png&wxfrom=5&wx_lazy=1

MNIST是最受欢迎的深度学习数据集之一，这是一个手写数字数据集，包含一组60,000个示例的训练集和一个包含10,000个示例的测试集。这是一个很好的数据库，用于在实际数据中尝试学习技术和深度识别模式，同时可以在数据预处理中花费最少的时间和精力。

大小： 50 MB

记录数量： 70,000张图片被分成了10个组。

SOTA： Capsules之间的动态路由

https://arxiv.org/pdf/1710.09829.pdf

2.MS-COCO
http://cocodataset.org/#home

640?wx_fmt=png

COCO是一个大型的、丰富的物体检测，分割和字幕数据集。它有几个特点：

对象分割；

在上下文中可识别；

超像素分割；

330K图像（> 200K标记）；

150万个对象实例；

80个对象类别；

91个类别；

每张图片5个字幕；

有关键点的250,000人；

大小：25 GB（压缩）

记录数量： 330K图像、80个对象类别、每幅图像有5个标签、25万个关键点。

SOTA：Mask R-CNN：https://arxiv.org/pdf/1703.06870.pdf

3.ImageNet
http://www.image-net.org/
640?wx_fmt=png

ImageNet是根据WordNet层次结构组织的图像数据集。WordNet包含大约100,000个单词，ImageNet平均提供了大约1000个图像来说明每个单词。

大小：150GB

记录数量：总图像是大约是1,500,000，每个都有多个边界框和相应的类标签。

SOTA：深度神经网络的聚合残差变换。

https://arxiv.org/pdf/1611.05431.pdf

4.Open Images数据集
https://github.com/openimages/dataset

640?wx_fmt=png

该数据集是一个包含近900万个图像URL的数据集，这些图像跨越了数千个类的图像级标签边框并且进行了注释。该数据集包含9,011,219张图像的训练集，41,260张图像的验证集以及125,436张图像的测试集。

大小：500 GB（压缩）

记录数量：9,011,219张超过5k标签的图像

SOTA：Resnet 101图像分类模型（在V2数据上训练）：模型检查点，检查点自述文件，推理代码。

5.VisualQA
http://www.visualqa.org/
640?wx_fmt=png

VQA是一个包含相关图像的开放式问题的数据集，这些问题需要理解视野和语言。这个数据集的一些有趣的特点是：

265,016张图片（COCO和抽象场景）；

每张图片至少有3个问题（平均5.4个问题）；

每个问题有10个基本事实答案；

每个问题有3个似乎合理（但可能不正确）的答案；

自动评估指标。

大小：25 GB（压缩）

记录数量：265,016张图片，每张图片至少3个问题，每个问题10个基本事实答案。

SOTA：视觉问答的技巧和诀窍：从2017年的挑战中学习

6.街景房屋号码（SVHN）
http://ufldl.stanford.edu/housenumbers/
640?wx_fmt=png

这是用于开发对象检测算法的真实世界的图像数据集，它需要最少的数据预处理。它与本列表中提到的MNIST数据集类似，但具有更多标签数据（超过600,000个图像），这些数据是从谷歌街景中查看的房屋号码中收集的。

大小：2.5 GB

记录数量：6,30,420张图片被分布在10个类中。

SOTA：虚拟对抗训练的分布平滑

7.CIFAR-10
http://www.cs.toronto.edu/~kriz/cifar.html
640?wx_fmt=png

该数据集是图像分类的另一个数据集，它由10个类的60,000个图像组成（每个类在上面的图像中表示为一行）。总共有50,000个训练图像和10,000个测试图像。数据集分为6个部分：5个训练批次和1个测试批次，每批有10,000个图像。

大小：170 MB

记录数量：60,000张图片被分为10个类。

SOTA：ShakeDrop正则化

8.Fashion--MNIST
https://github.com/zalandoresearch/fashion-mnist
640?wx_fmt=png

Fashion-MNIST包含60,000个训练图像和10,000个测试图像，它是一个类似MNIST的时尚产品数据库。开发人员认为MNIST已被过度使用，因此他们将其作为该数据集的直接替代品。每张图片都以灰度显示，并与10个类别的标签相关联。

大小：30 MB。

记录数量：70,000张图片被分为10个类。

SOTA：随机擦除数据增强

二、自然语言处理
9.IMDB评论 
http://ai.stanford.edu/~amaas/data/sentiment/
这是电影爱好者的梦幻数据集，它意味着二元情感分类，并具有比此领域以前的任何数据集更多的数据。除了训练和测试评估示例之外，还有更多未标记的数据供你使用。原始文本和预处理的单词格式包也包括在内。

大小：80 MB。

记录数量： 25,000个电影评论训练，25,000个测试

SOTA：学习结构化文本表示

10.二十个新闻组（Twenty Newsgroups）https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups
顾名思义，该数据集包含有关新闻组的信息。为了管理这个数据集，从20个不同的新闻组中获取了1000篇Usenet文章。这些文章具有典型特征，如主题行，签名和引号。

大小：20 MB

记录数量：来自20个新闻组的20,000条消息。

SOTA：用于文本分类的非常深的卷积网络，

11.Sentiment140
http://help.sentiment140.com/for-students/
Sentiment140是一个可用于情感分析的数据集。它是一个流行的数据集，它能让你的NLP旅程更加完美。情绪已经从数据中预先删除，最终的数据集具有以下6个特征：

推文的极性（polarity of the tweet）。

推文的ID。

推文的日期。

查询。

推文的文本。

大小：80 MB（压缩）。

记录数量：160,000条推文。

SOTA：评估最先进的情感数据集的最新情绪模型

12.WordNet
https://wordnet.princeton.edu/
在上面的ImageNet数据集中提到，WordNet是一个包含英文synsets的大型数据库。Synsets是同义词组，每个描述不同的概念。WordNet的结构使其成为NLP非常有用的工具。

大小：10 MB

记录数量：通过少量“概念关系”将117,000个同义词集与其他同义词集相关联。

SOTA：Wordnet：现状和前景

13.Yelp评论
https://www.yelp.com/dataset
这是Yelp为了学习目的而发布的一个开放数据集。它由数百万用户评论，商业属性和来自多个大都市地区的超过20万张照片组成。这是一个非常常用的全球NLP挑战数据集。

大小：2.66 GB JSON，2.9 GB SQL和7.5 GB照片（全部压缩）

记录数：5,200,000条评论，174,000条商业属性，20万张照片。

SOTA：细心卷积(Attentive Convolution)

14.维基百科语料库
http://nlp.cs.nyu.edu/wikipedia-data/
该数据集是维基百科全文的集合。它包含来自400多万篇文章的将近19亿字。这个强大的NLP数据集你可以通过单词，短语或段落本身的一部分进行搜索。

大小：20 MB。

记录数：4,400,000篇文章，19亿字。

SOTA：打破Softmax Bottelneck：高级RNN语言模型

15.博客作者身份语料库
http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm
此数据集包含从数千名博主收集的博客帖子，并且已从blogger.com收集。每个博客都作为一个单独的文件提供，每个博客至少包含200次常用英语单词。

大小：300 MB

记录数：681,288个帖子，超过1.4亿字。

SOTA：用于大规模作者归属的字符级和多通道卷积神经网络

16.欧洲语言的机器翻译数据集
http://statmt.org/wmt18/index.html
该数据集包含四种欧洲语言的训练数据，它存在的任务是改进当前的翻译方法。你训练以下任何语言对：

法语——英语；

西班牙语——英语；

德语——英语；

捷克语——英语。

大小：15 GB

记录数量：约30,000,000个句子及其翻译。

SOTA：Attention就是你所需要的

三、音频/语音数据集
17.免费口语数字数据集
https://github.com/Jakobovski/free-spoken-digit-dataset
此列表中的另一项是由MNIST数据集启发！这是为了解决识别音频样本中的口头数字的任务而创建的。这是一个开放的数据集，所以希望随着人们继续贡献更多样本，它会不断增长。目前，它包含以下特点：

3个扬声器；

1500个录音（每个扬声器每个数字50个）；

英语发音；

大小：10 MB。

记录数量：1500个音频样本。

SOTA：使用采样级CNN架构的基于原始波形的音频分类

18.免费音乐档案（FMA）
https://github.com/mdeff/fma
FMA是音乐分析的数据集，该数据集由full-length和HQ音频、预先计算的特征以及音轨和用户级元数据组成。它是一个开放数据集，用于评估MIR中的几个任务。以下是数据集连同其包含的csv文件列表：

tracks.csv：106,574首曲目的每首曲目元数据，如ID，标题，艺术家，流派，标签和播放次数。

genres.csv：163种风格的ID与他们的名字和父母（用于推断流派层次和顶级流派）。

features.csv：用librosa提取的共同特征 。

echonest.csv：由Echonest （现在的 Spotify）为13,129首音轨的子集提供的音频功能 。

大小：1000 GB

记录数量：约100,000 tracks

SOTA：学习从音频中识别音乐风格

19.舞厅（Ballroom）：http://mtg.upf.edu/ismir2004/contest/tempoContest/node5.html
该数据集包含舞厅跳舞音频文件，以真实音频格式提供了许多舞蹈风格的一些特征摘录。 以下是数据集的一些特征：

实例总数：698；

持续时间：约30秒；

总持续时间：约20940秒；

大小： 14GB（压缩）

记录数量：约700个音频样本

SOTA：考虑到不同类型音乐风格的多模型方法来打败追踪

20.百万歌曲数据集
https://labrosa.ee.columbia.edu/millionsong/
在百万歌曲数据集是音频功能和元数据的一百万当代流行音乐曲目可自由可用的集合。 其目的是：

鼓励对扩大到商业规模的算法进行研究；

为评估研究提供参考数据集；

作为使用API创建大型数据集的捷径（例如Echo Nest的）；

帮助新研究人员在MIR领域开始工作；

数据集的核心是一百万首歌曲的特征分析和元数据。该数据集不包含任何音频，只包含派生的功能。示例音频可以通过使用哥伦比亚大学提供的代码从7digital等服务中获取。

大小： 280 GB

记录数量：一百万首歌曲！

SOTA：百万歌曲数据集挑战推荐系统的初步研究

21.LibriSpeech
http://www.openslr.org/12/
该数据集是包含大约1000小时的英语语音的大型语料库。这些数据来自LibriVox项目的有声读物。它已被分割并正确对齐，如果你正在寻找一个起点，请查看已准备好的声学模型，这些模型在kaldi-asr.org和语言模型上进行了训练，适合评估，网址为：http://www.openslr.org/11/。

大小：60 GB

记录数： 1000小时的演讲。

SOTA：基于信件的语音识别与门控通信

22.VoxCeleb
http://www.robots.ox.ac.uk/~vgg/data/voxceleb/
VoxCeleb是一个大型的说话人识别数据集。它包含约1,200名来自YouTube视频的约10万个话语，数据大部分是性别平衡的（男性占55％）。名人跨越不同的口音，职业和年龄，开发和测试集之间没有重叠。对于隔离和识别哪个超级巨星来说，这是一个有趣的用例。

大小： 150 MB

记录数： 1,251位名人的100,000条话语。

SOTA：VoxCeleb：一个大型说话人识别数据集

四、数据集的问题实践
23.Twitter情绪分析
https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/
仇恨以种族主义和性别歧视为形式的言论已成为麻烦，重要的是将这类推文与其他人分开。在这个实践问题中，我们提供既有正常又有仇恨推文的Twitter数据。你作为数据科学家的任务是确定推文是仇恨推文，哪些不是。

大小： 3 MB。

记录数量： 31,962条推文。

24.印度演员的年龄检测
https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/
对于任何深度学习爱好者来说，这是一个令人着迷的挑战。该数据集包含数千个印度演员的图像，你的任务是确定他们的年龄。所有图像都是手动选择的，并从视频帧中剪切，导致尺度，姿势，表情，照度，年龄，分辨率，遮挡和化妆的高度可变性。

大小： 48 MB（压缩）。

记录数：训练集中的19,906幅图像和测试集中的6636幅图像。

SOTA：深入学习 - 解决年龄检测问题

25.城市声音分类
https://datahack.analyticsvidhya.com/contest/practice-problem-urban-sound-classification/
这个数据集包含超过8000个来自10个不同城市声音摘录。这个实践问题旨在向你介绍常见分类方案中的音频处理。

大小：训练集 - 3 GB（压缩），测试集 - 2 GB（压缩）

记录数： 来自10个城市的8732个声音标注的声音片段（<= 4s）



CN-Celeb 无约束条件说话人识别的中文语音数据集
原创海上机械师 最后发布于2020-02-24 22:59:34 阅读数 448  收藏
展开
CN-Celeb 无约束条件说话人识别的中文语音数据集
数据源：http://www.openslr.org/82/

项目源：http://cslt.riit.tsinghua.edu.cn/mediawiki/index.php/CN-Celeb

文献：Fan Y, Kang J, Li L et al. CN-CELEB: a challenging Chinese speaker recognition dataset. arXiv preprint arXiv:1911.01799, 2019.

摘要
目的：研究无约束条件下的自动说话人识别，换句话说，speaker recognition in the wild。
数据与方法：建立了CN-Celeb数据集，该数据集包含130,000条语音段，1000位中国名人，11种语音体裁，短时语音段，共计274小时。CN-Celeb在i-vector/PLDA与x-vector/PLDA进行评测，并与VoxCeleb数据对比。
结果：在i-vector/PLDA与x-vector/PLDA两个算法上，CN-Celeb上EER高于10%，VoxCeleb上EER低于10%。
结论：CN-Celeb数据与VoxCeleb数据的区别显著；对于现阶段的说话人识别算法来说，CN-Celeb数据集更具挑战。

1. 引言
数十年的研究极大地提升了说话人识别系统的性能，然而无约束条件的说话人识别仍然难以达到可靠的水平。不确定的因素主要来自两方面，一是外在因素，二是内在因素，具体地，文本无关、多信道、环境噪声、说话人风格、生理健康状态。

传统的因子分析方法与概率线性可区分性分析、最新的深度学习方法在受约束数据集上的说话人识别性能表现良好，然而这些数据集没有充分体现出丰富的声学条件，例如DARPA、SWITCHBOARD、NIST SRE与Voxceleb。

研究无约束条件的说话人识别问题，“In The Wild”数据集是重要的基础。基于VoxCeleb数据集提供的自动化数据采集流程，清华大学收集了一份大规模的中文语音数据集CN-Celeb，该数据集有3个特点：

CN-Celeb专注中国名人，包含130,000+语音段，来自1000位。
CN-Celeb包含11种语音体裁，例如娱乐，访问，唱歌，戏剧，电影，视频博客，现场直播，演讲，戏剧，朗诵和广告，相比较VoxCeleb只是访问的语音，更具有无约束条件的代表性。
CN-Celeb涉及人工检测，语音段的准确性更高。
2. CN-Celeb 数据集
CN-Celeb数据集具有三个特性：专注中国人、复杂的体裁、质量保证。数据统计结果如下：

表1. 语音体裁分布
体裁	说话人数量	语音段数量	小时数
娱乐	483	22,064	33.67
访问	780	59,317	135.77
唱歌	318	12,551	28.83
戏剧	69	4,245	4.95
电影	62	2,749	2.20
视频博客	41	1,894	4.15
现场直播	129	8,747	16.35
演讲	122	8,401	36.22
戏剧	160	7,274	6.43
朗诵	41	2,747	4.98
广告	17	120	0.18
共计	1,000	130,109	273.73
表2. 语音段长度的分布
长度(秒)	语音段数量	占比
<2	41,658	32.0%
2-5	38,629	30.0%
5-10	23,497	18.0%
10-15	10,687	8.0%
15-20	5,334	4.0%
20-25	3,218	2.5%
25-30	1,991	1.5%
>30	5,095	4%
CN-Celeb与VoxCeleb数据统计的对比结果如下表所示，两者的差别如下：

更多的真实噪声，例如环境噪声、背景babbing、音乐、欢呼声与小声；
强的、覆盖说话人的背景，特别是戏剧与电影场景；
多数说话人有不同的说话流派，使得说话风格差异显著；
不同时间与不同设备记录的语音；
多数语音是短时的。
表3. CN-Celeb与VoxCeleb的比较
CN-Celeb	VocCeleb
数据源	bilibili.com	youtube.com
语言	中文	英语为主
体裁	11	访问为主
人数	1,000	7,363
语音数	130,109	1,281,762
小时数	274	2,794
人工检查	是	否
论文提及了获取数据的步骤，是一种两阶段的方式：

自动提取分段，

人工筛选有效分段，其中人工删选的效率为 1 小时内检查 1 小时的语音。

备注：个人知识水平有些，对自动提取部分的人脸检测、追踪、语音对齐等技术不熟悉，故不做介绍。

3. 说话人识别的实验
实验涉及的数据、方法及其设定如下：

数据：
评测集：SITW，来自VoxCeleb1；CN-Celeb(E)，共200人。
训练集：VoxCeleb，由VoxCeleb1与VoxCeleb2组成，除去SITW部分，1,236,567段语音；CN-Celeb(T)，共800人。
挑选的评测集：SITW(S)，将SITW重新分段，使其时长与CN-Celeb(E)相似。
挑选的训练集：VoxCeleb(L)，来自VoxCeleb，800人，与CN-Celeb(T)人数上相同。
方法及其设定：
i-vector：MFCC + CMN + VAD + UBM + i-vector + LDA + PLDA
x-vector：TDNN + LDA + PLDA
前端模型：i-vector与x-vector
后端模型：LDA与PLDA
实验结果分为两部分：

基准实验结果，i-vector与x-vector学习VoxCeleb数据集之后，在SITW、SITW(S)、CN-Celeb(E)上的性能评估，见表4所示。
不同训练数据的评估结果，当训练集为VoxCeleb、VoxCeleb(L)或CN-Celeb(T)，在SITW(S)、CN-Celeb(E)上的性能评估，见表5所示。
表4. i-vector与x-vector在三个评测数据集上的EER
训练集	评测集
系统	前端	后端	SITW	SITW(S)	CN-Celeb(E)
i-vector	VoxCeleb	VoxCeleb	5.30	7.30	19.05
x-vector	VoxCeleb	VoxCeleb	3.75	4.78	15.52
表5. 不同数据设定的EER
训练集	评测集
系统	前端	后端	SITW(S)	CN-Celeb(E)
i-vector	VoxCeleb	VoxCeleb(L)	8.34	17.43
CN-Celeb(T)	CN-Celeb(T)	14.87	14.24
VoxCeleb	CN-Celeb(T)	12.96	15.00
CN-Celeb(T)	VoxCeleb(L)	11.34	15.50
x-vector	VoxCeleb	VoxCeleb(L)	5.93	13.64
CN-Celeb(T)	CN-Celeb(T)	15.23	14.78
VoxCeleb	CN-Celeb(T)	10.72	11.99
CN-Celeb(T)	VoxCeleb(L)	12.68	15.62
作者：王瑞 同济大学 计算机系博士研究生

邮箱：rwang@tongji.edu.cn

CSDN：https://blog.csdn.net/i_love_home

Github：https://github.com/mechanicalsea

点赞 1
————————————————
版权声明：本文为CSDN博主「海上机械师」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/i_love_home/article/details/104487814


国内外深度学习开放数据集下载集合(值得收藏，不断更新)
 csdnzoutao 2018-05-08 17:43:03  8447  收藏 22
展开
国内外深度学习开放数据集下载集合(值得收藏，不断更新)
一、Image processing data set

1、MNIST ，是最流行的深度学习数据集之一。这是一个手写数字数据集，包含一个有着 60000 样本的训练集和一个有着 10000 样本的测试集。对于在现实世界数据上尝试学习技术和深度识别模式而言，这是一个非常好的数据库，且无需花费过多时间和精力进行数据预处理。

大小：约 50 MB

数量：70000 张图像，共分为 10 个类别。

Identify the Digits：Identify the Digits下载

MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges：mnist下载

2、Fashion-MNIST， 包含 60,000 个训练集图像和 10,000 个测试集图像。它是一个类似 MNIST 的时尚产品数据库。开发人员认为 MNIST 的使用次数太多了，因此他们把这个数据集用作 MNIST 的直接替代品。每张图像都以灰度显示，并具备一个标签（10 个类别之一）。

大小：30MB

数量：70,000 张图像，共 10 类

zalandoresearch/fashion-mnist：下载地址

3、PASCAL VOC挑战赛是视觉对象的分类识别和检测的一个基准测试，提供了检测算法和学习性能的标准图像注释数据集和标准的评估系统。PASCAL VOC图片集包括20个目录：人类；动物（鸟、猫、牛、狗、马、羊）；交通工具（飞机、自行车、船、公共汽车、小轿车、摩托车、火车）；室内（瓶子、椅子、餐桌、盆栽植物、沙发、电视）。PASCAL VOC挑战赛在2012年后便不再举办，但其数据集图像质量好，标注完备，非常适合用来测试算法性能。

数据集大小：~2GB

Visual Object Classes Challenge 2012 (VOC2012)：下载地址

4、VQA ，是一个包含图像开放式问题的数据集。这些问题的解答需要视觉和语言的理解。该数据集拥有下列有趣的特征：

大小：25GB（压缩后）

数量：265,016 张图像，每张图像至少 3 个问题，每个问题 10 个正确答案

Announcing the VQA Challenge 2018!：下载地址

5、COCO， 是一个大型数据集，用于目标检测、分割和标题生成。Announcing the VQA Challenge 2018!2、COCO 是一个大型数据集，用于目标检测、分割和标题生成。

大小：约 25 GB（压缩后）

数量：33 万张图像、80 个目标类别、每张图像 5 个标题、25 万张带有关键点的人像

Common Objects in Context：下载地址

6、CIFAR-10，该数据集也用于图像分类。它由 10 个类别共计 60,000 张图像组成（每个类在上图中表示为一行）。该数据集共有 50,000 张训练集图像和 10,000 个测试集图像。数据集分为 6 个部分——5 个训练批和 1 个测试批。每批含有 10,000 张图像。

大小：170MB

数量：60,000 张图像，共 10 类

http://www.cs.toronto.edu/~kriz/cifar.html：下载地址

7、ImageNet ，是根据 WordNet 层次来组织的图像数据集。WordNet 包含大约 10 万个短语，而 ImageNet 为每个短语提供平均约 1000 张描述图像。

大小：约 150 GB

数量：图像的总数约为 1,500,000；每一张图像都具备多个边界框和各自的类别标签。

http://www.image-net.org/：下载地址

ImageNet：下载地址

8、街景门牌号数据集（SVHN），这是一个现实世界数据集，用于开发目标检测算法。它需要最少的数据预处理过程。它与 MNIST 数据集有些类似，但是有着更多的标注数据（超过 600,000 张图像）。这些数据是从谷歌街景中的房屋门牌号中收集而来的。

大小：2.5GB

数量：6,30,420 张图像，共 10 类

The Street View House Numbers (SVHN) Dataset
：下载地址

9、Open Images ，是一个包含近 900 万个图像 URL 的数据集。这些图像使用包含数千个类别的图像级标签边界框进行了标注。该数据集的训练集包含 9,011,219 张图像，验证集包含 41,260 张图像，测试集包含 125,436 张图像。

大小：500GB（压缩后）~1.5GB（不包括图片）

数量：9,011,219 张图像，带有超过 5000 个标签

openimages/dataset：下载地址

10、机器标注的一个超大规模数据集，包含2亿图像。

We address the problem of large-scale annotation of web images. Our approach is based on the concept of visual synset, which is an organization of images which are visually-similar and semantically-related. Each visual synset represents a single prototypical visual concept, and has an associated set of weighted annotations. Linear SVM’s are utilized to predict the visual synset membership for unseen image examples, and a weighted voting rule is used to construct a ranked list of predicted annotations from a set of visual synsets. We demonstrate that visual synsets lead to better performance than standard methods on a new annotation database containing more than 200 million im- ages and 300 thousand annotations, which is the largest ever reported.

VisualSynset：下载地址

11、包含13万的图像的数据集。Scene categorization is a fundamental problem in computer vision. However, scene understanding research has been constrained by the limited scope of currently-used databases which do not capture the full variety of scene categories. Whereas standard databases for object categorization contain hundreds of different classes of objects, the largest available dataset of scene categories contains only 15 classes. In this paper we propose the extensive Scene UNderstanding (SUN) database that contains 899 categories and 130,519 images. We use 397 well-sampled categories to evaluate numerous state-of-the-art algorithms for scene recognition and establish new bounds of performance. We measure human scene classification performance on the SUN database and compare this with computational methods.

http://vision.princeton.edu/projects/2010/SUN/
​vision.princeton.edu
12、包含100万的图像，23000视频；微软亚洲研究院出品，质量应该有保障。

Microsoft Research – Emerging Technology, Computer, and Software Research
：下载地址

二、Natural Language Processing data setVisualSynset二、Natural Language Processing data setLarge-scale Scene Recognition from Abbey to Zoo
二、Natural Language Processing data setVisualSynset二、Natural Language Processing data set

1、IMDB 电影评论数据集，该数据集对于电影爱好者而言非常赞。它用于二元情感分类，目前所含数据超过该领域其他数据集。除了训练集评论样本和测试集评论样本之外，还有一些未标注数据可供使用。此外，该数据集还包括原始文本和预处理词袋格式。

大小：80 MB

数量：训练集和测试集各包含 25,000 个高度两极化的电影评论

Sentiment Analysis：下载地址

2、 欧洲语言机器翻译数据集 ，该数据集包含四种欧洲语言的训练数据，旨在改进当前的翻译方法。你可以使用以下任意语言对： 法语 - 英语 西班牙语 - 英语 德语 - 英语 捷克语 - 英语

大小： 约 15 GB

数量：约 30,000,000 个句子及对应的译文

2018 Third Conference on Machine Translation (WMT18)
​statmt.org：下载地址

3、WordNet，WordNet 是一个大型英语 synset 数据库。Synset 也就是同义词组，每组描述的概念不同。WordNet 的结构让它成为 NLP 中非常有用的工具。

大小：10 MB

数量：117,000 个同义词集

A Lexical Database for English：下载地址

4、Wikipedia Corpus，该数据集是维基百科全文的集合，包含来自超过 400 万篇文章的将近 19 亿单词。你能逐单词、逐短语、逐段地对其进行检索，这使它成为强大的 NLP 数据集。

大小：20 MB

数量：4,400,000 篇文章，包含 19 亿单词

Tagged and Cleaned Wikipedia (TC Wikipedia) and its Ngram：下载地址

5、Yelp 数据集，这是 Yelp 出于学习目的而发布的开放数据集。它包含数百万个用户评论、商业属性（businesses attribute）和来自多个大都市地区的超过 20 万张照片。该数据集是全球范围内非常常用的 NLP 挑战赛数据集。 ，

大小：2.66 GB JSON、2.9 GB SQL 和 7.5 GB 的照片（全部压缩后）

数量：5,200,000 个评论、174,000 份商业属性、200,000 张照片和 11 个大都市地区

Yelp Dataset：下载地址

6、Blog Authorship Corpus，该数据集包含从数千名博主那里收集到的博客文章，这些数据从 blogger.com 中收集而来。每篇博客都以一个单独的文件形式提供。每篇博客至少出现 200 个常用的英语单词。

大小：300 MB

数量：681,288 篇博文，共计超过 1.4 亿单词。

：下载地址

7、Twenty Newsgroups 数据集 ，顾名思义，该数据集涵盖新闻组相关信息，包含从 20 个不同新闻组获取的 20000 篇新闻组文档汇编（每个新闻组选取 1000 篇）。这些文章有着典型的特征，例如标题、导语。

大小：20MB

数量：来自 20 个新闻组的 20,000 篇报道

Twenty Newsgroups Data Set：下载地址

8、Sentiment140，是一个用于情感分析的数据集。这个流行的数据集能让你完美地开启自然语言处理之旅。数据中的情绪已经被预先清空。最终的数据集具备以下六个特征： 推文的情绪极性 推文的 ID 推文的日期 查询 推特的用户名 推文的文本

大小：80MB（压缩后）

数量： 1,60,000 篇推文

For Academics - Sentiment140 - A Twitter Sentiment Analysis Tool：下载地址

三、Audio / voice dataset

1、VoxCeleb， 是一个大型人声识别数据集。它包含来自 YouTube 视频的 1251 位名人的约 10 万段语音。数据基本上是性别平衡的（男性占 55％）。这些名人有不同的口音、职业和年龄。开发集和测试集之间没有重叠。对大明星所说的话进行分类并识别——这是一项有趣的工作。

大小：150 MB

数量：1251 位名人的 100,000 条语音

VoxCeleb dataset
：下载地址

2、Youtube-8M为谷歌开源的视频数据集，视频来自youtube，共计8百万个视频，总时长50万小时，4800类。为了保证标签视频数据库的稳定性和质量，谷歌只采用浏览量超过1000的公共视频资源。为了让受计算机资源所限的研究者和学生也可以用上这一数据库，谷歌对视频进行了预处理，并提取了帧级别的特征，提取的特征被压缩到可以放到一个硬盘中（小于1.5T）。

大小：~1.5TB

https://research.google.com/youtube8m/
：下载地址

3、Free Spoken Digit 数据集 ，这是本文又一个受 MNIST 数据集启发而创建的数据集！该数据集旨在解决识别音频样本中口述数字的任务。这是一个公开数据集，所以希望随着人们继续提供数据，它会不断发展。目前，它具备以下特点： 3 种人声 1500 段录音（每个人口述 0- 9 各 50 次） 英语发音

大小： 10 MB

数量： 1500 个音频样本 SOTA：《Raw Waveform-based Audio

Jakobovski/free-spoken-digit-dataset：下载地址
图标

4、Million Song 数据集，包含一百万首当代流行音乐的音频特征和元数据，可免费获取。其目的是： 鼓励研究商业规模的算法 为评估研究提供参考数据集 作为使用 API 创建大型数据集的捷径（例如 The Echo Nest API） 帮助入门级研究人员在 MIR 领域展开工作 数据集的核心是一百万首歌曲的特征分析和元数据。该数据集不包含任何音频，只包含导出要素。示例音频可通过哥伦比亚大学提供的代码（https://github.com/tb2332/MSongsDB/tree/master/Tasks_Demos/Preview7digital）从 7digital 等服务中获取。

大小：280 GB

数量：一百万首歌曲！

https://labrosa.ee.columbia.edu/millionsong/
：https://labrosa.ee.columbia.edu/millionsong/

5、FMA 是音乐分析数据集，由整首 HQ 音频、预计算的特征，以及音轨和用户级元数据组成。它是一个公开数据集，用于评估 MIR 中的多项任务。以下是该数据集包含的 csv 文件及其内容： tracks.csv：记录每首歌每个音轨的元数据，例如 ID、歌名、演唱者、流派、标签和播放次数，共计 106,574 首歌。 genres.csv：记录所有 163 种流派的 ID 与名称及上层风格名（用于推断流派层次和上层流派）。 features.csv：记录用 librosa 提取的常见特征。 echonest.csv：由 Echonest（现在的 Spotify）为 13,129 首音轨的子集提供的音频功能。

大小：约 1000 GB

数量：约 100,000 个音轨

：下载地址

6、Ballroom ， 该数据集包含舞厅的舞曲音频文件。它以真实音频格式提供了许多舞蹈风格的一些特征片段。以下是该数据集的一些特点： 实例总数：698 单段时长：约 30 秒 总时长：约 20940 秒 大小：14 GB（压缩后） 数量：约 700 个音频样本

Ballroom：下载地址

7、LibriSpeech，该数据集是一个包含约 1000 小时英语语音的大型语料库。数据来源为 LibriVox 项目的音频书籍。该数据集已经得到了合理地分割和对齐。如果你还在寻找起始点，那么点击 http://www.kaldi-asr.org/downloads/build/6/trunk/egs/查看在该数据集上训练好的声学模型，点击 http://www.openslr.org/11/查看适合评估的语言模型。

大小：约 60 GB

数量：1000 小时的语音

openslr.org
：http://www.openslr.org/12/
图标
四、综合数据集

1、雅虎发布的超大Flickr数据集，包含1亿多张图片。

The data collected so far represents the world largest multimedia metadata collection that is available for research on scalable similarity search techniques. CoPhIR consist of 106 million processed images. CoPhIR is now available to the research community to try and compare different indexing technologies for similarity search, with scalability being the key issue. Our use of the Flickr image content is compliant to the Creative Commons license. CoPhIR Test Collection is compliant to the European Recommendation 29/2001 CE, based on WIPO (World Intellectual Property Organization) Copyright Treaty and Performances and Phonograms Treaty, and to the current Italian law 68/2003. In order to access the CoPhIR distribution, the organizations (universities, research labs, etc.) interested in building experimentations on it will have to sign the enclosed CoPhIR Access Agreement and the CoPhIR Access Registration Form, sending the original signed document to us by mail. Please follow the instruction in the section “How to get CoPhIR Test Collection”. You will then receive Login and Password to download the required files.

CoPhIR - what is

http://cophir.isti.cnr.it/whatis.html

2、包含8000万的32x32图像，CIFAR-10和CIFAR-100便是从中挑选的。

The 79 million images are stored in one giant binary file, 227Gb insize. The metadata accompanying each image is also in a single giantfile, 57Gb in size. To read images/metadata from these files, we haveprovided some Matlab wrapper functions. There are two versions of the functions for reading image data: (i) loadTinyImages.m - plain Matlab function (no MEX), runs under32/64bits. Loads images in by image number. Use this by default. (ii) read_tiny_big_binary.m - Matlab wrapper for 64-bit MEXfunction. A bit faster and more flexible than (i), but requires a 64-bit machine. There are two types of annotation data: (i) Manual annotation data, sorted in annotations.txt, that holds thelabel of images manually inspected to see if image content agrees withnoun used to collect it. Some other information, such as searchengine, is also stored. This data is available for only a very smallportion of images. (ii) Automatic annotation data, stored in tiny_metadata.bin,consisting of information relating the gathering of the image,e.g. search engine, which page, url to thumbnail etc. This data isavailable for all 79 million images.

http://horatio.cs.nyu.edu/mit/tiny/data/index.html

3、The MIRFLICKR-25000 open evaluation project consists of 25000 images downloaded from the social photography site Flickr through its public API coupled with complete manual annotations, pre-computed descriptors and software for bag-of-words based similarity and classification and a matlab-like tool for exploring and classifying imagery.

800谷歌学术引文和3万9000的下载量来自大学（麻省理工学院、剑桥、斯坦福、牛津，哥伦比亚市，美国，新加坡，Tsinghua，东京大学，韩国科学技术院，等）和公司（IBM，微软，谷歌，雅虎！脸谱网、飞利浦、索尼、诺基亚等）

下载地址

以上就是一些国内外深度学习开放数据集下载集合。

更多数据集下载
参考地址：
https://zhuanlan.zhihu.com/p/35535460
https://www.kaggle.com/datasets
http://www.52ml.net/20458.html
